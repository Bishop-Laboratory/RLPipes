fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_sra <- content_sra$content
}
}
result <- XML::xmlToList(XML::xmlParse(content_sra))
# Need to map back to original entries -- very annoying...
# TODO: Figure out a better way to do this without user error issues
fltr <- reutils::make_flattener()
acc_matchs <- lapply(result, function(res_now) {
flt_res <- unlist(fltr(res_now))
acc_match <- accnow[which(accnow %in% flt_res)]
names(acc_match) <- res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
if (length(acc_match) > 1) {
stop("Multiple provided accessions (",paste0(acc_match, collapse = ", "),
") mapped to identical SRA entries: ",
res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID, ". This interferes with assigning",
" parameters for experimental conditions. Please remove these duplcates.")
}
return(acc_match)
})
acc_matchs <- unlist(acc_matchs, use.names = TRUE)
names(acc_matchs) <- gsub(names(acc_matchs), pattern = "EXPERIMENT_PACKAGE\\.", replacement = "")
map_2 <- data.frame("accessions_cleaned" = acc_matchs,
"sra_experiment" = names(acc_matchs), stringsAsFactors = FALSE)
map_merge <- merge(x = map_1, y = map_2, by = "accessions_cleaned", all = TRUE)
# Unpack experiment list
resList <- lapply(result, FUN = function(exp_now) {
# exp_now <- result[[19]]
SRX <- exp_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
SRRs <- unlist(exp_now$RUN_SET, use.names = FALSE)
SRRs <- unique(SRRs[grep(SRRs, pattern = "^[SE]RR[0-9]+$")])
new_exp_name <- paste0(SRRs, collapse = ",")
# TODO: see if there's some way to get condition info from SRA
condition <- exp_now$STUDY$IDENTIFIERS$PRIMARY_ID
out_name <- exp_now$SAMPLE$TITLE
if (is.null(out_name)) {
out_name <- "UNKNOWN"
}
sample_name <- paste0(SRX, "_", clean_str(out_name))
sample_tx <- exp_now$SAMPLE$SAMPLE_NAME$TAXON_ID
possible_genomes <- available_genomes[available_genomes$taxId == sample_tx,]
lib_type <- names(exp_now$EXPERIMENT$DESIGN$LIBRARY_DESCRIPTOR$LIBRARY_LAYOUT)
if ("PAIRED" %in% lib_type) {
paired_end <- TRUE
} else {
paired_end <- FALSE
}
if (! length(possible_genomes$UCSC_orgID)) {
stop("No UCSC genome assembly available for sample ", SRX, " with taxonomy ID: ", sample_tx)
}
genomes_available <- possible_genomes[which(possible_genomes$genes_available),]
if (! length(genomes_available$UCSC_orgID)) {
warning("No UCSC genome annotations available for sample ", SRX, " with taxonomy ID: ", sample_tx,
". Will not run steps which require annotations.")
genome <- possible_genomes$UCSC_orgID[which.max(possible_genomes$year)]
} else {
genome <- genomes_available$UCSC_orgID[which.max(genomes_available$year)]
}
read_length <- as.numeric(exp_now$RUN_SET$RUN$Statistics$Read["average"])
res_now <- data.frame(
sra_experiment = SRX,
experiment = new_exp_name,
genome = genome,
condition = condition,
paired_end = paired_end,
sample_name = sample_name,
out_name = out_name,
read_length = read_length
)
return(res_now)
})
res_df <- data.table::rbindlist(resList)
map_final <- merge(x = map_merge, y = res_df, by = "sra_experiment", all = TRUE)
})
load("RSeq_CLI/helpers/data/available_genomes.rda")
View(available_genomes)
# Unpack experiment list
resList <- lapply(result, FUN = function(exp_now) {
# exp_now <- result[[19]]
SRX <- exp_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
SRRs <- unlist(exp_now$RUN_SET, use.names = FALSE)
SRRs <- unique(SRRs[grep(SRRs, pattern = "^[SE]RR[0-9]+$")])
new_exp_name <- paste0(SRRs, collapse = ",")
# TODO: see if there's some way to get condition info from SRA
condition <- exp_now$STUDY$IDENTIFIERS$PRIMARY_ID
out_name <- exp_now$SAMPLE$TITLE
if (is.null(out_name)) {
out_name <- "UNKNOWN"
}
sample_name <- paste0(SRX, "_", clean_str(out_name))
sample_tx <- exp_now$SAMPLE$SAMPLE_NAME$TAXON_ID
possible_genomes <- available_genomes[available_genomes$taxId == sample_tx,]
lib_type <- names(exp_now$EXPERIMENT$DESIGN$LIBRARY_DESCRIPTOR$LIBRARY_LAYOUT)
if ("PAIRED" %in% lib_type) {
paired_end <- TRUE
} else {
paired_end <- FALSE
}
if (! length(possible_genomes$UCSC_orgID)) {
stop("No UCSC genome assembly available for sample ", SRX, " with taxonomy ID: ", sample_tx)
}
genomes_available <- possible_genomes[which(possible_genomes$genes_available),]
if (! length(genomes_available$UCSC_orgID)) {
warning("No UCSC genome annotations available for sample ", SRX, " with taxonomy ID: ", sample_tx,
". Will not run steps which require annotations.")
genome <- possible_genomes$UCSC_orgID[which.max(possible_genomes$year)]
} else {
genome <- genomes_available$UCSC_orgID[which.max(genomes_available$year)]
}
read_length <- as.numeric(exp_now$RUN_SET$RUN$Statistics$Read["average"])
res_now <- data.frame(
sra_experiment = SRX,
experiment = new_exp_name,
genome = genome,
condition = condition,
paired_end = paired_end,
sample_name = sample_name,
out_name = out_name,
read_length = read_length
)
return(res_now)
})
#### Bug testing ##
#accessions <- c("SRX2481503", "SRX2481504", "GSE134101", "SRP150774", "GSE127329", "SRS1466492")
#accessions <- c("SRX2918366", "SRX2918367", "GSM3936516", "SRX5129664")
#accessions <- c("SRX2918366", "SRX2918367", "GSM3936517", "GSM3936517", "GSM3936517", "SRX5129664", "GSM2550995")
#accessions <- c("SRR2019278")
# accessions <- public_ctr_accessions
# accessions <- samples_public$experiment
#accessions <- public_ctr_accessions
accessions <- "SRR3504393"
accessions <- unique(accessions)
# Convert GEO series to BioProject accessions
acc_gse <- accessions[grep(accessions, pattern = "^GSE[0-9]+$")]
if (length(acc_gse)) {
fail <- TRUE
while (fail) {
esearch_gse <- reutils::esearch(acc_gse, db = "gds")
if (length(as.character(esearch_gse$errors$error))) {
if (as.character(esearch_gse$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
}
}
if (length(esearch_gse$errors$errmsg)) {
stop(paste0(paste0(esearch_gse$errors$errmsg, collapse = ", ")), " not found")
}
fail <- TRUE
while (fail) {
content_bp <- reutils::efetch(esearch_gse)
if (length(as.character(content_bp$errors$error))) {
if (as.character(content_bp$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_bp <- content_bp$content
}
}
res_bp <- stringr::str_match_all(string = content_bp,
pattern = "/Traces/study/\\?acc=(PRJNA[0-9]+)")[[1]][,2]
res_gse <- stringr::str_match_all(string = content_bp,
pattern = "geo/series/GSE[0-9]+nnn/(GSE[0-9]+)/")[[1]][,2]
convert_ord <- order(match(res_gse, acc_gse)) # Need original series order
map_1 <- data.frame("accessions_original" = accessions,
"accessions_cleaned" = NA, stringsAsFactors = FALSE)
accessions[grep(accessions, pattern = "^GSE[0-9]+$")] <- res_bp[convert_ord]
map_1$accessions_cleaned <- accessions
} else {
map_1 <- data.frame("accessions_original" = accessions,
"accessions_cleaned" = accessions, stringsAsFactors = FALSE)
}
# Build chunks of 100 accessions
acc_list <- split(accessions, ceiling(seq_along(accessions)/100))
res_list_full <- lapply(acc_list, function (accnow) {
# Query all accessions in SRA
fail <- TRUE
while (fail) {
Sys.sleep(.5)
esearch_sra <- reutils::esearch(accnow, db = "sra")
if (length(as.character(esearch_sra$errors$error))) {
if (as.character(esearch_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
}
}
if (length(esearch_sra$errors$errmsg)) {
stop(paste0(paste0(esearch_sra$errors$errmsg, collapse = ", ")), " not found")
}
fail <- TRUE
while (fail) {
Sys.sleep(.5)
content_sra <- reutils::efetch(esearch_sra)
if (length(as.character(content_sra$errors$error))) {
if (as.character(content_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_sra <- content_sra$content
}
}
result <- XML::xmlToList(XML::xmlParse(content_sra))
# Need to map back to original entries -- very annoying...
# TODO: Figure out a better way to do this without user error issues
fltr <- reutils::make_flattener()
acc_matchs <- lapply(result, function(res_now) {
flt_res <- unlist(fltr(res_now))
acc_match <- accnow[which(accnow %in% flt_res)]
names(acc_match) <- res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
if (length(acc_match) > 1) {
stop("Multiple provided accessions (",paste0(acc_match, collapse = ", "),
") mapped to identical SRA entries: ",
res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID, ". This interferes with assigning",
" parameters for experimental conditions. Please remove these duplcates.")
}
return(acc_match)
})
acc_matchs <- unlist(acc_matchs, use.names = TRUE)
names(acc_matchs) <- gsub(names(acc_matchs), pattern = "EXPERIMENT_PACKAGE\\.", replacement = "")
map_2 <- data.frame("accessions_cleaned" = acc_matchs,
"sra_experiment" = names(acc_matchs), stringsAsFactors = FALSE)
map_merge <- merge(x = map_1, y = map_2, by = "accessions_cleaned", all = TRUE)
# Unpack experiment list
resList <- lapply(result, FUN = function(exp_now) {
# exp_now <- result[[19]]
SRX <- exp_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
SRRs <- unlist(exp_now$RUN_SET, use.names = FALSE)
SRRs <- unique(SRRs[grep(SRRs, pattern = "^[SE]RR[0-9]+$")])
new_exp_name <- paste0(SRRs, collapse = ",")
# TODO: see if there's some way to get condition info from SRA
condition <- exp_now$STUDY$IDENTIFIERS$PRIMARY_ID
out_name <- exp_now$SAMPLE$TITLE
if (is.null(out_name)) {
out_name <- "UNKNOWN"
}
sample_name <- paste0(SRX, "_", clean_str(out_name))
sample_tx <- exp_now$SAMPLE$SAMPLE_NAME$TAXON_ID
possible_genomes <- available_genomes[available_genomes$taxId == sample_tx,]
lib_type <- names(exp_now$EXPERIMENT$DESIGN$LIBRARY_DESCRIPTOR$LIBRARY_LAYOUT)
if ("PAIRED" %in% lib_type) {
paired_end <- TRUE
} else {
paired_end <- FALSE
}
if (! length(possible_genomes$UCSC_orgID)) {
stop("No UCSC genome assembly available for sample ", SRX, " with taxonomy ID: ", sample_tx)
}
genomes_available <- possible_genomes[which(possible_genomes$genes_available),]
if (! length(genomes_available$UCSC_orgID)) {
warning("No UCSC genome annotations available for sample ", SRX, " with taxonomy ID: ", sample_tx,
". Will not run steps which require annotations.")
genome <- possible_genomes$UCSC_orgID[which.max(possible_genomes$year)]
} else {
genome <- genomes_available$UCSC_orgID[which.max(genomes_available$year)]
}
read_length <- as.numeric(exp_now$RUN_SET$RUN$Statistics$Read["average"])
res_now <- data.frame(
sra_experiment = SRX,
experiment = new_exp_name,
genome = genome,
condition = condition,
paired_end = paired_end,
sample_name = sample_name,
out_name = out_name,
read_length = read_length
)
return(res_now)
})
res_df <- data.table::rbindlist(resList)
map_final <- merge(x = map_merge, y = res_df, by = "sra_experiment", all = TRUE)
})
res_df_full <- data.table::rbindlist(res_list_full)
res_df_full <- res_df_full[! is.na(res_df_full$experiment)]
res_df_full
accessions <- unique(accessions)
# Convert GEO series to BioProject accessions
acc_gse <- accessions[grep(accessions, pattern = "^GSE[0-9]+$")]
if (length(acc_gse)) {
fail <- TRUE
while (fail) {
esearch_gse <- reutils::esearch(acc_gse, db = "gds")
if (length(as.character(esearch_gse$errors$error))) {
if (as.character(esearch_gse$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
}
}
if (length(esearch_gse$errors$errmsg)) {
stop(paste0(paste0(esearch_gse$errors$errmsg, collapse = ", ")), " not found")
}
fail <- TRUE
while (fail) {
content_bp <- reutils::efetch(esearch_gse)
if (length(as.character(content_bp$errors$error))) {
if (as.character(content_bp$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_bp <- content_bp$content
}
}
res_bp <- stringr::str_match_all(string = content_bp,
pattern = "/Traces/study/\\?acc=(PRJNA[0-9]+)")[[1]][,2]
res_gse <- stringr::str_match_all(string = content_bp,
pattern = "geo/series/GSE[0-9]+nnn/(GSE[0-9]+)/")[[1]][,2]
convert_ord <- order(match(res_gse, acc_gse)) # Need original series order
map_1 <- data.frame("accessions_original" = accessions,
"accessions_cleaned" = NA, stringsAsFactors = FALSE)
accessions[grep(accessions, pattern = "^GSE[0-9]+$")] <- res_bp[convert_ord]
map_1$accessions_cleaned <- accessions
} else {
map_1 <- data.frame("accessions_original" = accessions,
"accessions_cleaned" = accessions, stringsAsFactors = FALSE)
}
# Build chunks of 100 accessions
acc_list <- split(accessions, ceiling(seq_along(accessions)/100))
res_list_full <- lapply(acc_list, function (accnow) {
# Query all accessions in SRA
fail <- TRUE
while (fail) {
Sys.sleep(.5)
esearch_sra <- reutils::esearch(accnow, db = "sra")
if (length(as.character(esearch_sra$errors$error))) {
if (as.character(esearch_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
}
}
if (length(esearch_sra$errors$errmsg)) {
stop(paste0(paste0(esearch_sra$errors$errmsg, collapse = ", ")), " not found")
}
fail <- TRUE
while (fail) {
Sys.sleep(.5)
content_sra <- reutils::efetch(esearch_sra)
if (length(as.character(content_sra$errors$error))) {
if (as.character(content_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_sra <- content_sra$content
}
}
result <- XML::xmlToList(XML::xmlParse(content_sra))
# Need to map back to original entries -- very annoying...
# TODO: Figure out a better way to do this without user error issues
fltr <- reutils::make_flattener()
acc_matchs <- lapply(result, function(res_now) {
flt_res <- unlist(fltr(res_now))
acc_match <- accnow[which(accnow %in% flt_res)]
names(acc_match) <- res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
if (length(acc_match) > 1) {
stop("Multiple provided accessions (",paste0(acc_match, collapse = ", "),
") mapped to identical SRA entries: ",
res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID, ". This interferes with assigning",
" parameters for experimental conditions. Please remove these duplcates.")
}
return(acc_match)
})
acc_matchs <- unlist(acc_matchs, use.names = TRUE)
names(acc_matchs) <- gsub(names(acc_matchs), pattern = "EXPERIMENT_PACKAGE\\.", replacement = "")
map_2 <- data.frame("accessions_cleaned" = acc_matchs,
"sra_experiment" = names(acc_matchs), stringsAsFactors = FALSE)
map_merge <- merge(x = map_1, y = map_2, by = "accessions_cleaned", all = TRUE)
#### Bug testing ##
#accessions <- c("SRX2481503", "SRX2481504", "GSE134101", "SRP150774", "GSE127329", "SRS1466492")
#accessions <- c("SRX2918366", "SRX2918367", "GSM3936516", "SRX5129664")
#accessions <- c("SRX2918366", "SRX2918367", "GSM3936517", "GSM3936517", "GSM3936517", "SRX5129664", "GSM2550995")
#accessions <- c("SRR2019278")
# accessions <- public_ctr_accessions
# accessions <- samples_public$experiment
#accessions <- public_ctr_accessions
accessions <- "SRR3504393"
accessions <- unique(accessions)
# Convert GEO series to BioProject accessions
acc_gse <- accessions[grep(accessions, pattern = "^GSE[0-9]+$")]
res_df_full
acc_gse
map_1 <- data.frame("accessions_original" = accessions,
"accessions_cleaned" = accessions, stringsAsFactors = FALSE)
map_1
# Build chunks of 100 accessions
acc_list <- split(accessions, ceiling(seq_along(accessions)/100))
acc_list
accnow <- acc_list[1]
accnow <- acc_list[[1]]
# Query all accessions in SRA
fail <- TRUE
while (fail) {
Sys.sleep(.5)
esearch_sra <- reutils::esearch(accnow, db = "sra")
if (length(as.character(esearch_sra$errors$error))) {
if (as.character(esearch_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
}
}
if (length(esearch_sra$errors$errmsg)) {
stop(paste0(paste0(esearch_sra$errors$errmsg, collapse = ", ")), " not found")
}
fail <- TRUE
while (fail) {
Sys.sleep(.5)
content_sra <- reutils::efetch(esearch_sra)
if (length(as.character(content_sra$errors$error))) {
if (as.character(content_sra$errors$error) == "HTTP error: Status 429; Too Many Requests") {
fail <- TRUE
Sys.sleep(1)
}
} else {
fail <- FALSE
content_sra <- content_sra$content
}
}
result <- XML::xmlToList(XML::xmlParse(content_sra))
result
# Need to map back to original entries -- very annoying...
# TODO: Figure out a better way to do this without user error issues
fltr <- reutils::make_flattener()
acc_matchs <- lapply(result, function(res_now) {
flt_res <- unlist(fltr(res_now))
acc_match <- accnow[which(accnow %in% flt_res)]
names(acc_match) <- res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
if (length(acc_match) > 1) {
stop("Multiple provided accessions (",paste0(acc_match, collapse = ", "),
") mapped to identical SRA entries: ",
res_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID, ". This interferes with assigning",
" parameters for experimental conditions. Please remove these duplcates.")
}
return(acc_match)
})
acc_matchs <- unlist(acc_matchs, use.names = TRUE)
acc_matchs
names(acc_matchs) <- gsub(names(acc_matchs), pattern = "EXPERIMENT_PACKAGE\\.", replacement = "")
map_2 <- data.frame("accessions_cleaned" = acc_matchs,
"sra_experiment" = names(acc_matchs), stringsAsFactors = FALSE)
map_merge <- merge(x = map_1, y = map_2, by = "accessions_cleaned", all = TRUE)
map_merge
exp_now <- result[[1]]
SRX <- exp_now$EXPERIMENT$IDENTIFIERS$PRIMARY_ID
SRRs <- unlist(exp_now$RUN_SET, use.names = FALSE)
SRRs <- unique(SRRs[grep(SRRs, pattern = "^[SE]RR[0-9]+$")])
new_exp_name <- paste0(SRRs, collapse = ",")
# TODO: see if there's some way to get condition info from SRA
condition <- exp_now$STUDY$IDENTIFIERS$PRIMARY_ID
out_name <- exp_now$SAMPLE$TITLE
if (is.null(out_name)) {
out_name <- "UNKNOWN"
}
sample_name <- paste0(SRX, "_", clean_str(out_name))
sample_tx <- exp_now$SAMPLE$SAMPLE_NAME$TAXON_ID
sample_tx
possible_genomes <- available_genomes[available_genomes$taxId == sample_tx,]
possible_genomes
# Special processing for yeast genome... which is incorrectly identified
possible_genomes <- available_genomes[available_genomes$taxId %in% c("4932", "559292"),]
View(possible_genomes)
lib_type <- names(exp_now$EXPERIMENT$DESIGN$LIBRARY_DESCRIPTOR$LIBRARY_LAYOUT)
if ("PAIRED" %in% lib_type) {
paired_end <- TRUE
} else {
paired_end <- FALSE
}
if (! length(possible_genomes$UCSC_orgID)) {
stop("No UCSC genome assembly available for sample ", SRX, " with taxonomy ID: ", sample_tx)
}
genomes_available <- possible_genomes[which(possible_genomes$genes_available),]
if (! length(genomes_available$UCSC_orgID)) {
warning("No UCSC genome annotations available for sample ", SRX, " with taxonomy ID: ", sample_tx,
". Will not run steps which require annotations.")
genome <- possible_genomes$UCSC_orgID[which.max(possible_genomes$year)]
} else {
genome <- genomes_available$UCSC_orgID[which.max(genomes_available$year)]
}
read_length <- as.numeric(exp_now$RUN_SET$RUN$Statistics$Read["average"])
res_now <- data.frame(
sra_experiment = SRX,
experiment = new_exp_name,
genome = genome,
condition = condition,
paired_end = paired_end,
sample_name = sample_name,
out_name = out_name,
read_length = read_length
)
res_now
